{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muito semelhante ao Train:\n",
    "# Importante: se alguma coisa do train for modificada, modifique aqui também!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ler Base de dados\n",
    "## CUIDADO COM O SEPARADOR DO CSV (trocar ; por ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('our_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['seller_id'] = data['seller_id'].apply(str)\n",
    "data['category_id'] = data['category_id'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar label da feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar as feature columns categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ad_type_description = tf.feature_column.categorical_column_with_hash_bucket('ad_type_description',hash_bucket_size=3)\n",
    "shipping_id = tf.feature_column.categorical_column_with_identity('shipping_id', num_buckets=8)\n",
    "category_id = tf.feature_column.categorical_column_with_hash_bucket('category_id', hash_bucket_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NÃO PASSE MAIS DE 10 PRODUTOS DE UMA VEZ!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seller_id = tf.feature_column.categorical_column_with_hash_bucket('seller_id', hash_bucket_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passar as feature columns categoricas para embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ad_type_description = tf.feature_column.embedding_column(ad_type_description, dimension=3)\n",
    "shipping_id = tf.feature_column.embedding_column(shipping_id, dimension=8)\n",
    "category_id = tf.feature_column.embedding_column(category_id, dimension=300)\n",
    "seller_id = tf.feature_column.embedding_column(seller_id, dimension=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar feature columns numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price = tf.feature_column.numeric_column('price')\n",
    "\n",
    "sold_quantity_0 = tf.feature_column.numeric_column('sold_qty_0')\n",
    "sold_quantity_1 = tf.feature_column.numeric_column('sold_qty_1')\n",
    "sold_quantity_2 = tf.feature_column.numeric_column('sold_qty_2')\n",
    "sold_quantity_3 = tf.feature_column.numeric_column('sold_qty_3')\n",
    "sold_quantity_4 = tf.feature_column.numeric_column('sold_qty_4')\n",
    "sold_quantity_5 = tf.feature_column.numeric_column('sold_qty_5')\n",
    "sold_last_week = tf.feature_column.numeric_column('sold_last_week')\n",
    "\n",
    "position_0 = tf.feature_column.numeric_column('pos_0')\n",
    "position_1 = tf.feature_column.numeric_column('pos_1')\n",
    "position_2 = tf.feature_column.numeric_column('pos_2')\n",
    "position_3 = tf.feature_column.numeric_column('pos_3')\n",
    "position_4 = tf.feature_column.numeric_column('pos_4')\n",
    "position_5 = tf.feature_column.numeric_column('pos_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completar feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = [ad_type_description,shipping_id,category_id,seller_id,price,sold_quantity_0,\n",
    "             sold_quantity_1,sold_quantity_2,sold_quantity_3,sold_quantity_4,sold_quantity_5,\n",
    "             position_0,position_1,position_2,position_3,position_4,position_5,sold_last_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo (O modelo salva automaticamente após ser treinado)\n",
    "# CUIDADO COM O NUMERO DE NEURONIOS, TEM QUE SER IGUAL AO TREINAMENTO!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_tf_random_seed': 1, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_session_config': None, '_model_dir': './model', '_keep_checkpoint_max': 5, '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier([18],feature_columns=feat_cols,n_classes=2,model_dir=\"./model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input da Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_func=tf.estimator.inputs.pandas_input_fn(x=x_data,batch_size=len(x_data),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\model.ckpt-36000\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(pred_func)\n",
    "prediction = list(prediction)\n",
    "final_preds = [pred['class_ids'][0] for pred in prediction]\n",
    "print(final_preds)\n",
    "print(len(final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva as previsões para serem unidas à base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.savetxt(\"prediction.csv\", final_preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
